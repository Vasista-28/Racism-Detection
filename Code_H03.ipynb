{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:25:48.850166Z",
     "iopub.status.busy": "2021-08-10T07:25:48.849741Z",
     "iopub.status.idle": "2021-08-10T07:26:02.057406Z",
     "shell.execute_reply": "2021-08-10T07:26:02.056396Z",
     "shell.execute_reply.started": "2021-08-10T07:25:48.850083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in c:\\programdata\\anaconda3\\lib\\site-packages (0.14.9)\n",
      "Requirement already satisfied: py-params>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->params-flow>=0.8.0->bert-for-tf2) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:02.059517Z",
     "iopub.status.busy": "2021-08-10T07:26:02.059192Z",
     "iopub.status.idle": "2021-08-10T07:26:02.904752Z",
     "shell.execute_reply": "2021-08-10T07:26:02.903914Z",
     "shell.execute_reply.started": "2021-08-10T07:26:02.059478Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:02.908622Z",
     "iopub.status.busy": "2021-08-10T07:26:02.908348Z",
     "iopub.status.idle": "2021-08-10T07:26:08.596202Z",
     "shell.execute_reply": "2021-08-10T07:26:08.595304Z",
     "shell.execute_reply.started": "2021-08-10T07:26:02.908594Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import bert \n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:08.598204Z",
     "iopub.status.busy": "2021-08-10T07:26:08.597861Z",
     "iopub.status.idle": "2021-08-10T07:26:10.266708Z",
     "shell.execute_reply": "2021-08-10T07:26:10.265788Z",
     "shell.execute_reply.started": "2021-08-10T07:26:08.598168Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_val = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.268634Z",
     "iopub.status.busy": "2021-08-10T07:26:10.268245Z",
     "iopub.status.idle": "2021-08-10T07:26:10.319505Z",
     "shell.execute_reply": "2021-08-10T07:26:10.318526Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.268591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.321261Z",
     "iopub.status.busy": "2021-08-10T07:26:10.320872Z",
     "iopub.status.idle": "2021-08-10T07:26:10.348267Z",
     "shell.execute_reply": "2021-08-10T07:26:10.347315Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.321212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_val.info())\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"label\", data = df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.350427Z",
     "iopub.status.busy": "2021-08-10T07:26:10.349817Z",
     "iopub.status.idle": "2021-08-10T07:26:10.381411Z",
     "shell.execute_reply": "2021-08-10T07:26:10.380365Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.350380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.info())\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.386178Z",
     "iopub.status.busy": "2021-08-10T07:26:10.385737Z",
     "iopub.status.idle": "2021-08-10T07:26:10.393931Z",
     "shell.execute_reply": "2021-08-10T07:26:10.392336Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.386142Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred_proba):\n",
    "    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred_proba >= 0.5), 4))\n",
    "    print('F1_SCORE: ', round(f1_score(y_test, y_pred_proba >= 0.5, average = \"macro\"), 4)) \n",
    "    print('ROC_AUC_SCORE: ', round(roc_auc_score(y_test, y_pred_proba), 4)) #Receiver Operating Characteristic Curve \n",
    "    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred_proba >= 0.5),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.397065Z",
     "iopub.status.busy": "2021-08-10T07:26:10.396248Z",
     "iopub.status.idle": "2021-08-10T07:26:20.195952Z",
     "shell.execute_reply": "2021-08-10T07:26:20.194943Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.397026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removes Punctuations\n",
    "def remove_punctuations(data):\n",
    "    punct_tag=re.compile(r'[^\\w\\s]')\n",
    "    data=punct_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes HTML syntaxes\n",
    "def remove_html(data):\n",
    "    html_tag=re.compile(r'<.*?>')\n",
    "    data=html_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes URL data\n",
    "def remove_url(data):\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes Emojis\n",
    "def remove_emoji(data):\n",
    "    emoji_clean= re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    data=emoji_clean.sub(r'',data)\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_html(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_url(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_emoji(z))\n",
    "\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_html(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_url(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_emoji(z))\n",
    "\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_html(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_url(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_emoji(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:20.198062Z",
     "iopub.status.busy": "2021-08-10T07:26:20.197659Z",
     "iopub.status.idle": "2021-08-10T07:26:29.894639Z",
     "shell.execute_reply": "2021-08-10T07:26:29.893810Z",
     "shell.execute_reply.started": "2021-08-10T07:26:20.198019Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_abb(data):\n",
    "    data = re.sub(r\"he's\", \"he is\", data)\n",
    "    data = re.sub(r\"there's\", \"there is\", data)\n",
    "    data = re.sub(r\"We're\", \"We are\", data)\n",
    "    data = re.sub(r\"That's\", \"That is\", data)\n",
    "    data = re.sub(r\"won't\", \"will not\", data)\n",
    "    data = re.sub(r\"they're\", \"they are\", data)\n",
    "    data = re.sub(r\"Can't\", \"Cannot\", data)\n",
    "    data = re.sub(r\"wasn't\", \"was not\", data)\n",
    "    data = re.sub(r\"don\\x89Ûªt\", \"do not\", data)\n",
    "    data= re.sub(r\"aren't\", \"are not\", data)\n",
    "    data = re.sub(r\"isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"What's\", \"What is\", data)\n",
    "    data = re.sub(r\"haven't\", \"have not\", data)\n",
    "    data = re.sub(r\"hasn't\", \"has not\", data)\n",
    "    data = re.sub(r\"There's\", \"There is\", data)\n",
    "    data = re.sub(r\"He's\", \"He is\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"You're\", \"You are\", data)\n",
    "    data = re.sub(r\"I'M\", \"I am\", data)\n",
    "    data = re.sub(r\"shouldn't\", \"should not\", data)\n",
    "    data = re.sub(r\"wouldn't\", \"would not\", data)\n",
    "    data = re.sub(r\"i'm\", \"I am\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªm\", \"I am\", data)\n",
    "    data = re.sub(r\"I'm\", \"I am\", data)\n",
    "    data = re.sub(r\"Isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"Here's\", \"Here is\", data)\n",
    "    data = re.sub(r\"you've\", \"you have\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªve\", \"you have\", data)\n",
    "    data = re.sub(r\"we're\", \"we are\", data)\n",
    "    data = re.sub(r\"what's\", \"what is\", data)\n",
    "    data = re.sub(r\"couldn't\", \"could not\", data)\n",
    "    data = re.sub(r\"we've\", \"we have\", data)\n",
    "    data = re.sub(r\"it\\x89Ûªs\", \"it is\", data)\n",
    "    data = re.sub(r\"doesn\\x89Ûªt\", \"does not\", data)\n",
    "    data = re.sub(r\"It\\x89Ûªs\", \"It is\", data)\n",
    "    data = re.sub(r\"Here\\x89Ûªs\", \"Here is\", data)\n",
    "    data = re.sub(r\"who's\", \"who is\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªve\", \"I have\", data)\n",
    "    data = re.sub(r\"y'all\", \"you all\", data)\n",
    "    data = re.sub(r\"can\\x89Ûªt\", \"cannot\", data)\n",
    "    data = re.sub(r\"would've\", \"would have\", data)\n",
    "    data = re.sub(r\"it'll\", \"it will\", data)\n",
    "    data = re.sub(r\"we'll\", \"we will\", data)\n",
    "    data = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", data)\n",
    "    data = re.sub(r\"We've\", \"We have\", data)\n",
    "    data = re.sub(r\"he'll\", \"he will\", data)\n",
    "    data = re.sub(r\"Y'all\", \"You all\", data)\n",
    "    data = re.sub(r\"Weren't\", \"Were not\", data)\n",
    "    data = re.sub(r\"Didn't\", \"Did not\", data)\n",
    "    data = re.sub(r\"they'll\", \"they will\", data)\n",
    "    data = re.sub(r\"they'd\", \"they would\", data)\n",
    "    data = re.sub(r\"DON'T\", \"DO NOT\", data)\n",
    "    data = re.sub(r\"That\\x89Ûªs\", \"That is\", data)\n",
    "    data = re.sub(r\"they've\", \"they have\", data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"should've\", \"should have\", data)\n",
    "    data = re.sub(r\"You\\x89Ûªre\", \"You are\", data)\n",
    "    data = re.sub(r\"where's\", \"where is\", data)\n",
    "    data = re.sub(r\"Don\\x89Ûªt\", \"Do not\", data)\n",
    "    data = re.sub(r\"we'd\", \"we would\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"weren't\", \"were not\", data)\n",
    "    data = re.sub(r\"They're\", \"They are\", data)\n",
    "    data = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªll\", \"you will\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªd\", \"I would\", data)\n",
    "    data = re.sub(r\"let's\", \"let us\", data)\n",
    "    data = re.sub(r\"it's\", \"it is\", data)\n",
    "    data = re.sub(r\"can't\", \"cannot\", data)\n",
    "    data = re.sub(r\"don't\", \"do not\", data)\n",
    "    data = re.sub(r\"you're\", \"you are\", data)\n",
    "    data = re.sub(r\"i've\", \"I have\", data)\n",
    "    data = re.sub(r\"that's\", \"that is\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"doesn't\", \"does not\",data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"didn't\", \"did not\", data)\n",
    "    data = re.sub(r\"ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"you'll\", \"you will\", data)\n",
    "    data = re.sub(r\"I've\", \"I have\", data)\n",
    "    data = re.sub(r\"Don't\", \"do not\", data)\n",
    "    data = re.sub(r\"I'll\", \"I will\", data)\n",
    "    data = re.sub(r\"I'd\", \"I would\", data)\n",
    "    data = re.sub(r\"Let's\", \"Let us\", data)\n",
    "    data = re.sub(r\"you'd\", \"You would\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"Ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"Haven't\", \"Have not\", data)\n",
    "    data = re.sub(r\"Could've\", \"Could have\", data)\n",
    "    data = re.sub(r\"youve\", \"you have\", data)  \n",
    "    data = re.sub(r\"donå«t\", \"do not\", data)  \n",
    "    return data\n",
    "    \n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_abb(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_abb(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_abb(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.896358Z",
     "iopub.status.busy": "2021-08-10T07:26:29.896023Z",
     "iopub.status.idle": "2021-08-10T07:26:29.909742Z",
     "shell.execute_reply": "2021-08-10T07:26:29.908897Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.896323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n",
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n",
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train.head(5))\n",
    "print(df_val.shape)\n",
    "print(df_val.head(5))\n",
    "print(df_test.shape)\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDetectionData:\n",
    "    DATA_COLUMN,  LABEL_COLUMN  = \"tweet\",\"label\"\n",
    "\n",
    "    def __init__(self, train, val, test, tokenizer: FullTokenizer, classes, max_seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = 0\n",
    "        self.classes = classes\n",
    "\n",
    "        ((self.train_x, self.train_y), (self.val_x, self.val_y), (self.test_x, self.test_y)) = map(self._prepare, [train, val, test])\n",
    "\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        self.train_x, self.val_x, self.test_x = map(self._pad, [self.train_x, self.val_x, self.test_x])\n",
    "\n",
    "    def _prepare(self, df):\n",
    "        x, y = [], []\n",
    "    \n",
    "        for non, row in tqdm(df.iterrows()):\n",
    "            text, label =\\\n",
    "                row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
    "\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] ## Tokens beigning and ending specified by separation of tokens.\n",
    "\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens) ## Convert Tokens to IDs\n",
    "\n",
    "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "\n",
    "            x.append(token_ids)\n",
    "            y.append(self.classes.index(label))\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def _pad(self, ids):\n",
    "        x = []\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)] ## -2 as ignoring tokens provided by bert\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids)) ## padding by zeros\n",
    "            x.append(np.array(input_ids))\n",
    "        \n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_V0(bert_output):\n",
    "    net = Conv1D(128, 7, activation='relu',padding='same')(bert_output)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(256, 5, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(512, 3, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(128, activation='relu')(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiLSTM_V0(bert_output):\n",
    "    net = Bidirectional(LSTM(units=32, return_sequences=True,))(bert_output)\n",
    "    net = GlobalAveragePooling1D()(net)\n",
    "    net = Dense(20, activation='relu')(net)\n",
    "    net = Dropout(rate=0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_V0(bert_output):\n",
    "    net = LSTM(units=32, return_sequences=True,)(bert_output)\n",
    "    net = GlobalAveragePooling1D()(net)\n",
    "    net = Dense(20, activation='relu')(net)\n",
    "    net = Dropout(rate=0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM_V0(bert_output):\n",
    "    net = Dropout(0.3)(bert_output)\n",
    "    net = Conv1D(200, 5, activation='relu')(net)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = LSTM(100)(net)\n",
    "    net = Dropout(0.3)(net)\n",
    "    net = Dense(16,activation='relu')(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM_V1(bert_output):\n",
    "\n",
    "    # channel 1\n",
    "    net = Conv1D(filters=128, kernel_size=3*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    a = LSTM(128)(net)\n",
    "\n",
    "    # channel 2\n",
    "    net = Conv1D(filters=128, kernel_size=5*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    b = LSTM(128)(net)\n",
    "\n",
    "    # channel 3\n",
    "    net = Conv1D(filters=128, kernel_size=7*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    c = LSTM(128)(net)\n",
    "\n",
    "    # channel 4\n",
    "    net = Conv1D(filters=128, kernel_size=9*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    d = LSTM(128)(net)\n",
    "\n",
    "    merged = concatenate([a,b,c,d])\n",
    "    dense = Dense(100, activation='relu')(merged)\n",
    "    drop = Dropout(0.2)(dense)\n",
    "    outputs = Dense(1, activation='sigmoid')(merged)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_CNN_V0(bert_output):\n",
    "    net = Bidirectional(LSTM(128, return_sequences=True))(bert_output)\n",
    "    net = Conv1D(128, 7, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(256, 5, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(512, 3, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(128, activation='relu')(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, model_ver, max_seq_len, bert_checkpnt_file):\n",
    "\n",
    "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read()) ## Reading bert config\n",
    "        bert_params = map_stock_config_to_params(bc) ## Mapping parameters \n",
    "        bert_params.adapter_size = None # Adapter size helps tune Bert model faster\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "    ## Creat dictionary\n",
    "    choose_model = {'CNN':{0: CNN_V0},\n",
    "                    'BiLSTM':{0: BiLSTM_V0},\n",
    "                    'LSTM':{0: LSTM_V0},\n",
    "                    'CNN+LSTM':{0: CNN_LSTM_V0, 1: CNN_LSTM_V1},\n",
    "                    'LSTM+CNN':{0: LSTM_CNN_V0},}\n",
    "    \n",
    "    ## Specifying input\n",
    "    input_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "        \n",
    "    outputs = choose_model[model_name][model_ver](bert_output)\n",
    "\n",
    "    model = keras.Model(input_ids, outputs)\n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "    load_stock_weights(bert, bert_checkpnt_file) ##Loading the weights from bert chckpoint file\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"uncased_L-12_H-768_A-12\"\n",
    "# uncased_L-4_H-512_A-8\n",
    "# uncased_L-12_H-768_A-12\n",
    "\n",
    "#!wget  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
    "#!unzip {bert_model_name}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bert_model.ckpt\n",
      "./bert_config.json\n",
      "./vocab.txt\n"
     ]
    }
   ],
   "source": [
    "bert_model_path = \"./\"\n",
    "bert_checkpnt_file = os.path.join(bert_model_path, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_path, \"bert_config.json\")\n",
    "bert_vocab_file = os.path.join(bert_model_path, \"vocab.txt\")\n",
    "print(bert_checkpnt_file)\n",
    "print(bert_config_file)\n",
    "print(bert_vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'say', 'nothing', 'is', 'impossible', ',', 'but', 'i', 'do', 'nothing', 'everyday']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2111, 2360, 2498, 2003, 5263, 1010, 2021, 1045, 2079, 2498, 10126]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = FullTokenizer(vocab_file=bert_vocab_file)\n",
    "tokens = tokenizer.tokenize(\"People say nothing is impossible, but I do nothing everyday\")\n",
    "print(tokens)\n",
    "tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31962it [00:11, 2857.55it/s]\n",
      "31962it [00:09, 3267.24it/s]\n",
      "31962it [00:09, 3201.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "classes = [0, 1]\n",
    "max_seq_len = 72\n",
    "data = IntentDetectionData(df_train, df_val, df_test, tokenizer, classes, max_seq_len)\n",
    "print(data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b9bf3d753fefe854781e52229fcc2b6d37fd5cec0eed166290fc2ac2cd3389d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
